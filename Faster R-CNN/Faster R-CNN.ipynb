{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66a283ea",
   "metadata": {},
   "source": [
    "# **Faster R-CNN – Detección de elementos arquitectónicos**\n",
    "\n",
    "### **Faster R-CNN con Optuna + PreloadedDataset**\n",
    "\n",
    "**Objetivo:** Detectar puertas, ventanas, balcones y railing  \n",
    "**Dataset:** Dataset_Final (anotaciones YOLO)  \n",
    "**Características:**\n",
    "- Optimización automática de hiperparámetros con Optuna\n",
    "- Carga de imágenes en RAM para acelerar\n",
    "- Evaluación con mAP@0.5 y mAP@0.5:0.95\n",
    "- Guardado de resultados y modelos en carpetas `exp01`, `exp02`, …\n",
    "- Dashboard de comparación de métricas y pérdidas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eec64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomprimir dataset\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = \"/kaggle/input/tu_dataset/Dataset_Final.zip\"  # ruta donde esta el zip\n",
    "extract_path = \"/kaggle/working/Dataset_Final\"  # donde se descomprime\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd66fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip --quiet\n",
    "\n",
    "# PyTorch y Torchvision (GPU compatible)\n",
    "!pip install torch torchvision torchaudio --quiet\n",
    "\n",
    "# Optuna para HPO\n",
    "!pip install optuna --quiet\n",
    "\n",
    "# PyCOCOTools para métricas de detección de objetos\n",
    "!pip install pycocotools --quiet\n",
    "\n",
    "# OpenCV y Matplotlib\n",
    "!pip install opencv-python matplotlib --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52872f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor  \n",
    "from torchvision.ops import box_iou\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfc6a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# Si la salida es Device: cuda ya esta Pytorch + cuda funcionando\n",
    "# No reinstalar Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4838c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas en Kaggle\n",
    "DATASET_ROOT = \"/kaggle/working/Dataset_Final\"\n",
    "\n",
    "TRAIN_IMG_DIR = os.path.join(DATASET_ROOT, \"train/images\")\n",
    "TRAIN_LBL_DIR = os.path.join(DATASET_ROOT, \"train/labels\")\n",
    "VAL_IMG_DIR = os.path.join(DATASET_ROOT, \"valid/images\")\n",
    "VAL_LBL_DIR = os.path.join(DATASET_ROOT, \"valid/labels\")\n",
    "TEST_IMG_DIR = os.path.join(DATASET_ROOT, \"test/images\")\n",
    "TEST_LBL_DIR = os.path.join(DATASET_ROOT, \"test/labels\")\n",
    "\n",
    "EXPERIMENT_ROOT = \"/kaggle/working/Faster_Experiments\"  # guardar modelos y logs\n",
    "os.makedirs(EXPERIMENT_ROOT, exist_ok=True)\n",
    "\n",
    "NUM_CLASSES = 5  # 4 clases + fondo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d168ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PreloadedDataset(Dataset):\n",
    "    def __init__(self, img_dir, lbl_dir, img_size=640):\n",
    "        self.img_dir = img_dir\n",
    "        self.lbl_dir = lbl_dir\n",
    "        self.img_size = img_size\n",
    "\n",
    "        self.img_files = sorted([\n",
    "            f for f in os.listdir(img_dir)\n",
    "            if f.lower().endswith((\".jpg\", \".png\"))\n",
    "        ])\n",
    "\n",
    "        if len(self.img_files) == 0:\n",
    "            raise RuntimeError(\"No hay imágenes en el directorio\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_files[idx]\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        lbl_path = os.path.join(self.lbl_dir, img_name.rsplit(\".\", 1)[0] + \".txt\")\n",
    "\n",
    "        # -------- Imagen --------\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        img = cv2.resize(img, (self.img_size, self.img_size))\n",
    "        h, w = self.img_size, self.img_size\n",
    "\n",
    "        img_tensor = torch.from_numpy(img).float().permute(2, 0, 1) / 255.0\n",
    "\n",
    "        # -------- Labels --------\n",
    "        boxes, labels = self.load_yolo_labels(lbl_path, w, h)\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "\n",
    "        return img_tensor, target\n",
    "\n",
    "    def load_yolo_labels(self, path, w, h):\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            return (\n",
    "                torch.zeros((0, 4), dtype=torch.float32),\n",
    "                torch.zeros((0,), dtype=torch.int64)\n",
    "            )\n",
    "\n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                cls = int(parts[0])\n",
    "                x, y, bw, bh = map(float, parts[1:])\n",
    "\n",
    "                x1 = (x - bw / 2) * w\n",
    "                y1 = (y - bh / 2) * h\n",
    "                x2 = (x + bw / 2) * w\n",
    "                y2 = (y + bh / 2) * h\n",
    "\n",
    "                boxes.append([x1, y1, x2, y2])\n",
    "                labels.append(cls)\n",
    "\n",
    "        if len(boxes) == 0:\n",
    "            return (\n",
    "                torch.zeros((0, 4), dtype=torch.float32),\n",
    "                torch.zeros((0,), dtype=torch.int64)\n",
    "            )\n",
    "\n",
    "        return (\n",
    "            torch.tensor(boxes, dtype=torch.float32),\n",
    "            torch.tensor(labels, dtype=torch.int64)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c85c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para mAP@0.5 y mAP@0.5:0.95\n",
    "def compute_map50_95(model, data_loader, device):\n",
    "    model.eval()\n",
    "    ious_all = {0.5:[], 0.55:[], 0.6:[], 0.65:[], 0.7:[], 0.75:[], 0.8:[], 0.85:[], 0.9:[], 0.95:[]}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, targets in data_loader:\n",
    "            imgs = [img.to(device) for img in imgs]\n",
    "            outputs = model(imgs)\n",
    "            for output, target in zip(outputs, targets):\n",
    "                if len(output[\"boxes\"]) == 0 or len(target[\"boxes\"]) == 0:\n",
    "                    continue\n",
    "                iou = box_iou(output[\"boxes\"].cpu(), target[\"boxes\"])\n",
    "                for t in ious_all.keys():\n",
    "                    max_iou_per_gt = iou.max(dim=0)[0]\n",
    "                    ious_all[t].extend(max_iou_per_gt.tolist())\n",
    "\n",
    "    map50 = sum([x>=0.5 for x in ious_all[0.5]]) / max(len(ious_all[0.5]),1)\n",
    "    map50_95 = sum([sum([x>=t for t in ious_all.keys()])/len(ious_all) for x in zip(*ious_all.values())]) / max(len(ious_all[0.5]),1)\n",
    "    \n",
    "    return map50, map50_95\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b21702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear datasets (precarga en RAM)\n",
    "train_dataset = PreloadedDataset(TRAIN_IMG_DIR, TRAIN_LBL_DIR, img_size=640)\n",
    "val_dataset   = PreloadedDataset(VAL_IMG_DIR, VAL_LBL_DIR, img_size=640)\n",
    "\n",
    "# Protección mínima\n",
    "if len(train_dataset) == 0:\n",
    "    raise RuntimeError(\"Train dataset vacío\")                                              \n",
    "\n",
    "if len(val_dataset) == 0:\n",
    "    print(\"Warning: Validation dataset vacío\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e87ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-2, log=True)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"AdamW\"])\n",
    "\n",
    "    batch_size = 4\n",
    "    epochs = 8\n",
    "    \n",
    "    # Carpeta para guardar los trials\n",
    "    trial_dir = os.path.join(EXPERIMENT_ROOT, f\"trial_{trial.number}\")\n",
    "    os.makedirs(trial_dir, exist_ok=True)\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=lambda x: tuple(zip(*x)),\n",
    "        num_workers=4  #num_workers=0  En kaggle por estabilidad\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=lambda x: tuple(zip(*x)),\n",
    "        num_workers=4  #num_workers=0  En kaggle por estabilidad\n",
    "    )\n",
    "\n",
    "    # Modelo\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "    # Congelar backbone\n",
    "    for param in model.backbone.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(\n",
    "        in_features,\n",
    "        NUM_CLASSES\n",
    "    )\n",
    "\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "    optimizer = (\n",
    "        torch.optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
    "        if optimizer_name == \"Adam\"\n",
    "        else torch.optim.AdamW(params, lr=lr, weight_decay=weight_decay)\n",
    "    )\n",
    "\n",
    "    # Entrenamiento\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for imgs, targets in train_loader:\n",
    "            imgs = [img.to(DEVICE) for img in imgs]\n",
    "            targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            loss_dict = model(imgs, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += losses.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        epoch_losses.append(avg_loss)\n",
    "        \n",
    "        # Map50 y pruning (estrategia)****\n",
    "        if epoch % 2 == 0:  # Evaluar map50 cada 2 epochs\n",
    "            map50, map50_95 = compute_map50_95(model, val_loader, DEVICE)\n",
    "        \n",
    "            # Activar pruner solo desde epoch 4 en adelante\n",
    "            if epoch >= 4:\n",
    "                trial.report(1 - map50, epoch)\n",
    "                if trial.should_prune():\n",
    "                    raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "\n",
    "    # Guardar losses del trial\n",
    "    with open(os.path.join(trial_dir, \"losses.json\"), \"w\") as f:\n",
    "        json.dump(epoch_losses, f, indent=4)\n",
    "\n",
    "    # Evaluación\n",
    "    map50, map50_95 = compute_map50_95(model, val_loader, DEVICE)\n",
    "\n",
    "    metrics = {\n",
    "        \"map50\": map50,\n",
    "        \"map50_95\": map50_95,\n",
    "        \"lr\": lr,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"optimizer\": optimizer_name\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(trial_dir, \"metrics.json\"), \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "        \n",
    "    # Guardar modelo del trial\n",
    "    torch.save(model.state_dict(), os.path.join(trial_dir, \"model.pth\"))\n",
    "    \n",
    "    return 1 - map50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d5bde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear estudio con Successive Halving Pruner\n",
    "pruner = optuna.pruners.SuccessiveHalvingPruner()\n",
    "study = optuna.create_study(direction=\"minimize\", pruner=pruner)\n",
    "\n",
    "# Ejecutar Optuna\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"Mejor configuración encontrada:\")\n",
    "print(study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d73a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dashboard comparativo entre trials\n",
    "exp_dirs = sorted([d for d in os.listdir(EXPERIMENT_ROOT) if d.startswith(\"trial_\")])\n",
    "\n",
    "maps50, maps50_95 = [], []\n",
    "losses_all = []\n",
    "\n",
    "for d in exp_dirs:\n",
    "    with open(os.path.join(EXPERIMENT_ROOT, d, \"metrics.json\"), \"r\") as f:\n",
    "        log = json.load(f)\n",
    "        maps50.append(log[\"map50\"])\n",
    "        maps50_95.append(log[\"map50_95\"])\n",
    "\n",
    "    with open(os.path.join(EXPERIMENT_ROOT, d, \"losses.json\"), \"r\") as f:\n",
    "        loss_log = json.load(f)\n",
    "        losses_all.append(loss_log)\n",
    "\n",
    "\n",
    "# Gráfico de pérdida por trial\n",
    "plt.figure(figsize=(10,5))\n",
    "for i, loss in enumerate(losses_all):\n",
    "    plt.plot(loss, label=exp_dirs[i])\n",
    "plt.title(\"Pérdida por epoch - todos los experiments\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Gráfico mAP@0.5 y mAP@0.5:0.95\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(range(len(exp_dirs)), maps50, label=\"mAP@0.5\")\n",
    "plt.bar(range(len(exp_dirs)), maps50_95, alpha=0.5, label=\"mAP@0.5:0.95\")\n",
    "plt.xticks(range(len(exp_dirs)), exp_dirs)\n",
    "plt.ylabel(\"mAP\")\n",
    "plt.title(\"Comparativa mAP por experiment\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770f03e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor trial\n",
    "best_trial_number = study.best_trial.number\n",
    "\n",
    "best_model_dir = os.path.join(EXPERIMENT_ROOT, f\"trial_{best_trial_number}\")\n",
    "\n",
    "print(f\"El mejor trial es trial_{best_trial_number} con los siguientes hiperparámetros:\")\n",
    "print(study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa8205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo entrenado del mejor trial\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "import torch\n",
    "\n",
    "# Inicializar el modelo con la misma arquitectura\n",
    "model = fasterrcnn_resnet50_fpn(weights=None)\n",
    "\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(\n",
    "        in_features,\n",
    "        NUM_CLASSES\n",
    "    )\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Cargar los pesos del mejor trial\n",
    "model.load_state_dict(torch.load(os.path.join(best_model_dir, \"model.pth\")))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba12c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar en validación\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "map50, map50_95 = compute_map50_95(model, val_loader, DEVICE)\n",
    "\n",
    "print(f\"Mejor modelo - mAP@0.5: {map50:.4f}\")\n",
    "print(f\"Mejor modelo - mAP@0.5:0.95: {map50_95:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887b476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de resultados del mejor modelo\n",
    "def show_predictions(model, dataset, device, class_names, num_images=5, score_threshold=0.5):\n",
    "    model.eval()\n",
    "    for i in range(num_images):\n",
    "        img, target = dataset[i]\n",
    "        with torch.no_grad():\n",
    "            pred = model([img.to(device)])\n",
    "        \n",
    "        img_np = img.permute(1,2,0).cpu().numpy()\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.imshow(img_np)\n",
    "        \n",
    "        # dibujar ground-truth\n",
    "        for box in target[\"boxes\"]:\n",
    "            x1, y1, x2, y2 = box\n",
    "            plt.gca().add_patch(plt.Rectangle((x1,y1), x2-x1, y2-y1, edgecolor='green', facecolor='none', linewidth=2))\n",
    "        \n",
    "        # dibujar predicciones\n",
    "        for box, score, label in zip(pred[0][\"boxes\"].cpu(), pred[0][\"scores\"].cpu(), pred[0][\"labels\"].cpu()):\n",
    "            if score > score_threshold:\n",
    "                x1, y1, x2, y2 = box\n",
    "                plt.gca().add_patch(plt.Rectangle((x1,y1), x2-x1, y2-y1, edgecolor='red', facecolor='none', linewidth=2))\n",
    "                class_name = class_names[label - 1]  # Ajustar según tu dataset\n",
    "                plt.text(\n",
    "                    x1, y1 - 5,\n",
    "                    f\"{class_name} ({score:.2f})\",\n",
    "                    color=\"red\",\n",
    "                    fontsize=9,\n",
    "                    backgroundcolor=\"white\"\n",
    "                )\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "class_names = [\"door\", \"window\", \"balcony\", \"railing\"]  \n",
    "show_predictions(model, val_dataset, DEVICE, class_names, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83716ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(os.path.join(best_model_dir, f\"pred_{i}.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b9c6d",
   "metadata": {},
   "source": [
    "Verde → ground-truth (cajas reales)\n",
    "\n",
    "Rojo → predicciones del modelo\n",
    "\n",
    "score > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c1fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Función para evaluar otras métricas (Precisión, Recall, F1, Matriz de Confusión)\n",
    "def evaluate_model(model, dataset, device, score_threshold=0.5, class_names=None):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, target in dataset:\n",
    "            pred = model([img.to(device)])\n",
    "            pred_labels = pred[0][\"labels\"].cpu()\n",
    "            pred_scores = pred[0][\"scores\"].cpu()\n",
    "\n",
    "            # Filtrar por score_threshold\n",
    "            keep = pred_scores > score_threshold\n",
    "            pred_labels = pred_labels[keep]\n",
    "\n",
    "            all_preds.extend(pred_labels.tolist())\n",
    "            all_labels.extend(target[\"labels\"].tolist())\n",
    "\n",
    "    # Precision, Recall, F1 por clase\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, labels=list(range(len(class_names))), zero_division=0\n",
    "    )\n",
    "\n",
    "    # Matriz de confusión\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=list(range(len(class_names))))\n",
    "\n",
    "    # Resultados como diccionario\n",
    "    results = {\n",
    "        \"precision\": dict(zip(class_names, precision)),\n",
    "        \"recall\": dict(zip(class_names, recall)),\n",
    "        \"f1\": dict(zip(class_names, f1)),\n",
    "        \"confusion_matrix\": cm.tolist()\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Evaluar el modelo\n",
    "class_names = [\"door\", \"window\", \"balcony\", \"railing\"]\n",
    "results = evaluate_model(model, val_dataset, DEVICE, score_threshold=0.5, class_names=class_names)\n",
    "\n",
    "# Guardar resultados en JSON\n",
    "results_file = os.path.join(best_model_dir, \"evaluation_results.json\")\n",
    "with open(results_file, \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "print(\"Resultados guardados en:\", results_file)\n",
    "print(json.dumps(results, indent=4))\n",
    "\n",
    "# Visualización de la matriz de confusión con matplotlib\n",
    "cm = np.array(results[\"confusion_matrix\"])\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "im = ax.imshow(cm, cmap=\"Blues\")\n",
    "\n",
    "# Mostrar valores encima de cada celda\n",
    "for i in range(len(class_names)):\n",
    "    for j in range(len(class_names)):\n",
    "        ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "ax.set_xticks(np.arange(len(class_names)))\n",
    "ax.set_yticks(np.arange(len(class_names)))\n",
    "ax.set_xticklabels(class_names)\n",
    "ax.set_yticklabels(class_names)\n",
    "ax.set_xlabel(\"Predicciones\")\n",
    "ax.set_ylabel(\"Ground-truth\")\n",
    "ax.set_title(\"Matriz de Confusión del Mejor Modelo\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
