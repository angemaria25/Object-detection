{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952cd8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# ==========================================\n",
    "# 1. TU CLASE DATASET (Con una pequeña mejora)\n",
    "# ==========================================\n",
    "class PreloadedDataset(Dataset):\n",
    "    def __init__(self, img_dir, lbl_dir, img_size=800): # Sugerencia: Subir a 800 para barandillas\n",
    "        self.img_dir = img_dir\n",
    "        self.lbl_dir = lbl_dir\n",
    "        self.img_size = img_size\n",
    "\n",
    "        self.img_files = sorted([\n",
    "            f for f in os.listdir(img_dir)\n",
    "            if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        lbl_path = os.path.join(self.lbl_dir, img_name.rsplit(\".\", 1)[0] + \".txt\")\n",
    "\n",
    "        # Imagen\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (self.img_size, self.img_size))\n",
    "        \n",
    "        # Tensor (C, H, W)\n",
    "        img_tensor = torch.from_numpy(img).float().permute(2, 0, 1) / 255.0\n",
    "\n",
    "        # Labels\n",
    "        boxes, labels = self.load_yolo_labels(lbl_path, self.img_size, self.img_size)\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"image_id\": torch.tensor([idx]) # Faster R-CNN a veces lo pide para evaluar\n",
    "        }\n",
    "\n",
    "        return img_tensor, target\n",
    "\n",
    "    def load_yolo_labels(self, path, w, h):\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            return torch.zeros((0, 4), dtype=torch.float32), torch.zeros((0,), dtype=torch.int64)\n",
    "\n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 5: continue\n",
    "                cls = int(float(parts[0]))\n",
    "                x, y, bw, bh = map(float, parts[1:])\n",
    "\n",
    "                # Conversión a Pascal VOC\n",
    "                x1 = (x - bw / 2) * w\n",
    "                y1 = (y - bh / 2) * h\n",
    "                x2 = (x + bw / 2) * w\n",
    "                y2 = (y + bh / 2) * h\n",
    "\n",
    "                # Validar que la caja tenga área (evita errores en ResNet)\n",
    "                if (x2 > x1) and (y2 > y1):\n",
    "                    boxes.append([x1, y1, x2, y2])\n",
    "                    labels.append(cls + 1) # 0 es fondo, tus clases son 1-5\n",
    "\n",
    "        if len(boxes) == 0:\n",
    "            return torch.zeros((0, 4), dtype=torch.float32), torch.zeros((0,), dtype=torch.int64)\n",
    "\n",
    "        return torch.tensor(boxes, dtype=torch.float32), torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "# ==========================================\n",
    "# 2. FUNCIÓN DE UNIÓN (CRÍTICA)\n",
    "# ==========================================\n",
    "# Faster R-CNN no acepta batches normales porque cada imagen tiene n cajas distintas\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# ==========================================\n",
    "# 3. MODELO Y CONFIGURACIÓN\n",
    "# ==========================================\n",
    "def get_model(num_classes):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "# ==========================================\n",
    "# 4. BUCLE DE ENTRENAMIENTO LOCAL\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuración de rutas\n",
    "    TRAIN_IMG_DIR = \"Data/train/images\"\n",
    "    TRAIN_LBL_DIR = \"Data/train/labels\"\n",
    "    VAL_IMG_DIR   = \"Data/val/images\"\n",
    "    VAL_LBL_DIR   = \"Data/val/labels\"\n",
    "\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    \n",
    "    # 1. Datasets y Loaders\n",
    "    # Nota: He subido img_size a 800 para detectar mejor los railings (barandillas)\n",
    "    train_dataset = PreloadedDataset(TRAIN_IMG_DIR, TRAIN_LBL_DIR, img_size=800)\n",
    "    val_dataset   = PreloadedDataset(VAL_IMG_DIR, VAL_LBL_DIR, img_size=800)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, \n",
    "                                    num_workers=2, collate_fn=collate_fn)\n",
    "\n",
    "    # 2. Modelo\n",
    "    num_classes = 5 # 4 clases + 1 fondo\n",
    "    model = get_model(num_classes)\n",
    "    model.to(device)\n",
    "\n",
    "    # 3. Optimización (SGD es mucho mejor para fachadas que Adam)\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "\n",
    "    # 4. Mixed Precision (Para que quepa en tus 6-8GB de VRAM)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    print(f\"Entrenando en {device} con ResNet-50...\")\n",
    "\n",
    "    for epoch in range(12):\n",
    "        model.train()\n",
    "        i = 0\n",
    "        for images, targets in train_loader:\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            with autocast():\n",
    "                loss_dict = model(images, targets)\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(losses).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            if i % 20 == 0:\n",
    "                print(f\"Epoch: {epoch}, Iter: {i}, Loss: {losses.item():.4f}\")\n",
    "            i += 1\n",
    "\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        # Guardar checkpoint\n",
    "        if epoch % 5 == 0:\n",
    "            torch.save(model.state_dict(), f\"checkpoint_epoch_{epoch}.pth\")\n",
    "\n",
    "    torch.save(model.state_dict(), \"faster_rcnn_fachadas_final.pth\")\n",
    "    print(\"¡Entrenamiento finalizado!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
